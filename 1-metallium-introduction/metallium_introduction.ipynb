{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5c7edc",
   "metadata": {},
   "source": [
    "# Introduction to TT-Metal\n",
    "\n",
    "## General Overview\n",
    "\n",
    "**TT-Metal** (AKA **TT-Metal** or **Metal**) is Tenstorrent's low-level SDK for programming Tensix processors. It sits at the foundation of Tenstorrent's software stack:\n",
    "\n",
    "- **TT-Forge / TT-MLIR**: High-level compilation frameworks for deploying neural networks.\n",
    "- **TTNN**: Library of kernels that implements common Machine Learning operations.\n",
    "- **TT-Metalium(Metalium)**: ⬅ **This tutorial focuses here** - Low-level programming interface for Tensix hardware.\n",
    "- **TT-LLK (Low Level Kernels)**: Hardware-specific kernel implementations.\n",
    "\n",
    "etal offers a set of abstractions between the host systems (e.g., desktop with x86 CPU) and the device. Its most important capability allows programmers to write **C++ programs**, called **kernels**, and execute these kernels on Tenstorrent hardware.\n",
    "\n",
    "This is similar to CUDA in spirit (programming language + runtime), but with a different architectural model emphasizing explicit data movement and local memory.\n",
    "\n",
    "## Introduction to TT-Metalium\n",
    "\n",
    "\n",
    "For production use, refer to the official installation guide: [INSTALLING.md](https://github.com/tenstorrent/tt-metal/blob/main/INSTALLING.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07e1b3-267a-4e2c-b934-07136206892d",
   "metadata": {},
   "source": [
    "The provided VMs should have a `tt-metal` folder with several directories such as:\n",
    "\n",
    "```\n",
    "- ttnn/ # TT-NN, contains library of operations and Kernels \n",
    "- tt_metal/ # Metalium-specific code, also contains TT-LLK as sub-repository\n",
    "- tt_stl/ # Standard library\n",
    "- tools/ # Debugging and profiling tools (e.g. tracy, triage)\n",
    "- tests/ # Python scripts for internal testing\n",
    "- docs/ # TT-Metaliumand TT-NN Documentation\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921aea85-d57b-49ea-898d-24347b595fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd tt-metal/\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c3f30-1af1-42d4-8970-027e2054fb26",
   "metadata": {},
   "source": [
    "## TT-Metalium Setup and Build\n",
    "\n",
    "We can build TT-Metalium using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2282f-006d-4790-bb15-6fe8c5c56913",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./build_metal.sh --build-tests --debug -e --enable-profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186bb95a-dbe1-4109-b050-cbac14465200",
   "metadata": {},
   "source": [
    "In this case, we also include serveral compile options which do the following:\n",
    "\n",
    "- `--build-tests` builds TT-Metalium and TT-NN tests (`test/` directory).\n",
    "- `--debug` set target to 'Debug' mode without optimization flags for host code (separate from kernel code compilation).\n",
    "- `-e` produce symbols (useful for IDEs such as Visual Studio Code).\n",
    "- `--enable-profiler`: enable device profiler.\n",
    "\n",
    "Building TT-Metalium from scratch takes a few minutes. \n",
    "\n",
    "## Testing\n",
    "\n",
    "Before running any test, set environment variables to use the correct python scripts, and define the path to TT-Metalium.\n",
    "The following commands assume that `tt-metal` (where TT-Metaliumhas been installed) is the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d066d65-880e-4b7d-af7f-e4a5f9c1e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source python_env/bin/activate\n",
    "export PYTHONPATH=$(pwd)\n",
    "export TT_METAL_HOME=$(pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd887c48-c709-472d-872f-7971046f50a0",
   "metadata": {},
   "source": [
    "Having built TT-Metaliumand TT-NN, we can tests basic operations like matrix multiplication (matmul) with the following python command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09d6bf-d915-4316-9b9f-f461d42e59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m pytest ./tests/ttnn/unit_tests/operations/matmul/test_matmul.py::test_tutorial_matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8956d09-2dec-4184-af33-ba2ed8300075",
   "metadata": {},
   "source": [
    "This command ensures that matmul operations execute correctly.\n",
    "These tests use the pytest library, hence `-m pytest` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d2ce3-875b-4ec6-b8f4-c15049fab95a",
   "metadata": {},
   "source": [
    "## Tenstorrent Programming Model Overview\n",
    "\n",
    "\n",
    "### Architecture: A Grid of Specialized Cores\n",
    "\n",
    "Tenstorrent chips are a massively parallel grid of interconnected cores, with different types of cores serving specialized functions:\n",
    "- **Tensix Cores**: The main compute units (where our kernels run).\n",
    "- **DRAM Banks**: Interface with off-chip memory (DRAM).\n",
    "- **Ethernet Cores**: For multi-chip communication and scaling operations and models to multiple chips.\n",
    "- **ARC/PCIe Cores**: Host I/O interfaces.\n",
    "\n",
    "In this tutorial, we will implement kernels on Tenstorrent hardware, focusing on Tensix Cores.\n",
    "\n",
    "![Wormhole Architecture](https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/source/common/images/tenstorrent-wormhole-logical-noc-diagram.webp)\n",
    "\n",
    "Each Tensix core contains the following components:\n",
    "- **5 Baby RISC-V CPUs** that fetch instructions, determine control flow, and configure data movement. \n",
    "  - 2 Data Movement cores (RISC-V 0 and 1): Handle NoC (Network-on-Chip) transfers.\n",
    "  - 3 Compute cores (Unpack, Math, Pack): Handle computation pipeline.\n",
    "\n",
    "These Baby RISC-V cores interact with the following components on Tensix cores:\n",
    "- **Matrix engine** (also known as **FPU**) - Specializes in matrix operations such as matrix multiplication and convolutions.\n",
    "- **Vector engine** (also known as **SFPU**) - Computes general purpose operations like element-wise, activation functions, data shuffling, etc.\n",
    "- **SRAM** (**L1**) - Local memory for each core (1.5MB for Wormhole and Blackhole). Unlike CPU, this _cache_ is managed manually by the programmer, similar to shared memory on CUDA.\n",
    "- **2 NoC Interfaces** - Reads and writes data across the chip, and is responsible for inter-core communication.\n",
    "\n",
    "A detailed introduction of the programming model can be found in the [Metalium Guide](https://github.com/tenstorrent/tt-metal/blob/main/METALIUM_GUIDE.md).\n",
    "\n",
    "### Programming Philosophy: Bottom-Up Design\n",
    "\n",
    "Operations on Tenstorrent hardware are typically designed from the **bottom up**:\n",
    "1. We start from a kernel on a single Tensix core.\n",
    "2. We schedule the kernel on multiple Tensix cores within the same chip. In some cases, this requires synchronizations between Tensix cores.\n",
    "3. We scale the kernel to multiple devices. This is critical for the developement of larger LLMs. \n",
    "\n",
    "To become familiar with TT-Metalium, we'll start from the bottom and study kernels on a single Tensix core.\n",
    "\n",
    "### Pipeline Dataflow Across Tensix Cores\n",
    "\n",
    "The typical data flow within each Tensix core follows a **pipeline pattern** through three different kernels:\n",
    "1. **Reader Kernel** (Data Movement): Reads data from DRAM into circular buffers. \n",
    "2. **Compute Kernel**: Processes data from circular buffers and performs computations.\n",
    "3. **Writer Kernel** (Data Movement): Writes results from circular buffers back to DRAM.\n",
    "\n",
    "![Kernel Pipeline](https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/source/common/images/tenstorrent-circular-buffer-send-data-cross-kernel-or-itself.webp)\n",
    "\n",
    "**Circular buffers** communicate and synchronize data between kernels.\n",
    "They act as FIFOs (First-In-First-Out) data structure, and enable Reader to read new data while compute processes previous data.\n",
    "\n",
    "This paradigm offers flexibility with data movement while allowing computation to overlap with data transfer.\n",
    "\n",
    "### Host and Device Components\n",
    "\n",
    "Developing kernels on Tenstorrent hardware requires code written for both the **device** and **host**.\n",
    "\n",
    "**1. Host code (C++)**:\n",
    "- Runs on your CPU\n",
    "- Opens and initializes the device.\n",
    "- Allocates memory buffers (DRAM and L1).\n",
    "- Configures circular buffers.\n",
    "- Compiles and loads kernels.\n",
    "- Sets runtime arguments (e.g. tell the kernel where to read and where to write data).\n",
    "- Enqueues kernels for execution.\n",
    "- Retrieves results from the device to the host.\n",
    "\n",
    "**2. Device code (C++ kernels)**: Runs on Tensix cores\n",
    "- Reader kernel: Fetches data from DRAM via the NoC (Network on Chip)\n",
    "- Compute kernel: Performs operations using the Matrix and Vector engines (FPU and SFPU)\n",
    "- Writer kernel: Writes results back to DRAM via NoC\n",
    "\n",
    "This is similar to other parallel programming APIs like **CUDA**, **OpenCL**, or **SYCL**, where you have host orchestration code and device kernels.\n",
    "\n",
    "### Typical Project Structure\n",
    "\n",
    "By convention, TT-Metalium examples follow this file organization:\n",
    "\n",
    "```\n",
    "example/\n",
    "├── example_host.cpp          # Host program\n",
    "└── kernels/\n",
    "    ├── dataflow/\n",
    "    │   ├── reader.cpp        # Reader kernel (RISC-V 0)\n",
    "    │   └── writer.cpp        # Writer kernel (RISC-V 1)\n",
    "    └── compute/\n",
    "        └── compute.cpp       # Compute kernel (Unpack/Math/Pack)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb5482-e727-4a58-b179-f47a962a2f9d",
   "metadata": {},
   "source": [
    "## Programming Examples: Adding Two Integers in RISC-V\n",
    "\n",
    "\n",
    "Having presented the basic principles of the Tenstorrent programming model, we will now look at specific examples.\n",
    "The most basic example of Tenstorrent kernel is the addition of two integers on a single Baby RISC-V. \n",
    "\n",
    "First, we build TT-Metalium with its programming examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b039e-fc02-409b-b9c4-b973ea664d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./build_metal.sh --build-tests --debug --build-programming-examples -e --enable-profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4f174-df44-4655-98c2-e78368cf6f98",
   "metadata": {},
   "source": [
    "Programming examples will build in `build_Release/programming_examples`.\n",
    "\n",
    "Verify that the programming examples have been built by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0486ac-eed7-4e1a-b4a6-c303b25997ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls build_Debug_tracy/programming_examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5638c1-5f93-4cf3-90e8-6092c71bd9a8",
   "metadata": {},
   "source": [
    "This following programming examples will be displayed: \n",
    "\n",
    "```\n",
    "- contributed\n",
    "- distributed\n",
    "- metal_example_add_2_integers_in_compute\n",
    "- metal_example_add_2_integers_in_riscv\n",
    "- metal_example_custom_sfpi_add\n",
    "- metal_example_custom_smoothstep\n",
    "- metal_example_eltwise_binary\n",
    "- metal_example_eltwise_sfpu\n",
    "- ...\n",
    "```\n",
    "\n",
    "### Adding Integers on Baby RISC-V\n",
    "\n",
    "As stated in previous sections, operations are designed around a Reader/Compute/Writer pipeline for maximum performance and leverage of Matrix and Vector engines.\n",
    "While Baby RISC-Vs are relatively slow and meant to coordinate data transfers, they still support arithmetic operations, and can be used to demonstrate a basic addition kernel such as the [following example](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/add_2_integers_in_riscv/add_2_integers_in_riscv.md).\n",
    "\n",
    "The `metal_example_add_2_integers_in_riscv` shows:\n",
    "- How to set up and execute a basic kernel with two inputs. \n",
    "- How to read data from DRAM on a reader kernel.\n",
    "- The addition of two integers on the Baby RISC-V.\n",
    "- How to write back output data to DRAM. \n",
    "\n",
    "\n",
    "### File Organization\n",
    "\n",
    "Having introduced the general outline of our example, we can verify its file structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0a040-bd58-46a2-8010-b66e34d39f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls tt_metal/programming_examples/add_2_integers_in_riscv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b819fa",
   "metadata": {},
   "source": [
    "\n",
    "should give the following\n",
    "```\n",
    "add_2_integers_in_riscv/\n",
    "├── add_2_integers_in_riscv.cpp          # Host program\n",
    "└── kernels/\n",
    "    ├── reader_writer_add_in_riscv.cpp   # Device kernel\n",
    "```\n",
    "\n",
    "In this case, we are using only 1 of the 5 Baby RISC-V cores, which means that we only need a single kernel.\n",
    "\n",
    "This example can be run using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2379e91-361c-482e-856b-31ef6f55cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./build_Debug_tracy/programming_examples/metal_example_add_2_integers_in_riscv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184d2bc-acf8-4391-85f0-83553bbbcf24",
   "metadata": {},
   "source": [
    "### Understanding the Program Structure\n",
    "\n",
    "This simple example show key components of TT-Metaliumprograms. Let's break down invidual parts:\n",
    "\n",
    "\n",
    "#### Host Program (`add_2_integers_in_riscv.cpp`)\n",
    "\n",
    "The host program configures data structures and coordinates the entire operation:\n",
    "\n",
    "1. **Device Setup**: Creates a 1x1 `MeshDevice` (description of a single hardware device) and gets a command queue for submitting work\n",
    "2. **Buffer Allocation**: Creates 6 buffers total:\n",
    "   - 3 DRAM buffers (src0, src1, dst)\n",
    "   - 3 L1 buffers for temporary storage during computation\n",
    "3. **Data Upload**: Writes input values (14 and 7) to DRAM buffers (Host -> Device)\n",
    "4. **Kernel Creation**: Compiles the reader/writer kernel for a single Tensix core (core 0)\n",
    "5. **Runtime Arguments**: Passes buffer addresses to the kernel\n",
    "6. **Execution**: Enqueues the program and waits for completion\n",
    "7. **Result Retrieval**: Reads back the result (21) from DRAM to host\n",
    "\n",
    "\n",
    "#### Device Kernel (`kernels/reader_writer_add_in_riscv.cpp`)\n",
    "\n",
    "The kernel runs on a Baby RISC-V core and performs three tasks:\n",
    "\n",
    "```cpp\n",
    "void kernel_main() {\n",
    "    // 1. Get runtime arguments (buffer addresses)\n",
    "    uint32_t src0_dram = get_arg_val<uint32_t>(0);\n",
    "    uint32_t src1_dram = get_arg_val<uint32_t>(1);\n",
    "    uint32_t dst_dram = get_arg_val<uint32_t>(2);\n",
    "    uint32_t src0_l1 = get_arg_val<uint32_t>(3);\n",
    "    uint32_t src1_l1 = get_arg_val<uint32_t>(4);\n",
    "    uint32_t dst_l1 = get_arg_val<uint32_t>(5);\n",
    "    // ... \n",
    "    \n",
    "    // 2. Read data from DRAM into L1 (local SRAM)\n",
    "    // Whereas DRAM is outside the chip, L1 memory is located inside the tensix core\n",
    "    // and has both lower latency and significantly higher bandwidth.\n",
    "    noc_async_read(src0_dram_noc_addr, src0_l1, sizeof(uint32_t));\n",
    "    noc_async_read(src1_dram_noc_addr, src1_l1, sizeof(uint32_t));\n",
    "    noc_async_read_barrier();  // Wait for transfers to complete\n",
    "    \n",
    "    // 3. Perform addition on RISC-V core.\n",
    "    // This read inputs from L1, compute addition, and store back result to L1\n",
    "    uint32_t* dat0 = (uint32_t*)src0_l1;\n",
    "    uint32_t* dat1 = (uint32_t*)src1_l1;\n",
    "    (*out0) = (*dat0) + (*dat1);  // 14 + 7 = 21\n",
    "    \n",
    "    // 4. Write result back to DRAM (operation is complete)\n",
    "    noc_async_write(dst_l1, dst_dram_noc_addr, sizeof(uint32_t));\n",
    "    noc_async_write_barrier();\n",
    "}\n",
    "```\n",
    "\n",
    "**Some important concepts:**\n",
    "- The **NoC (Network-on-Chip)** is the network of connections on the chip that are used to move (read/write) data from/to any location on the chip.\n",
    "- Read and writes are asynchronous: `noc_async_read` and `noc_async_write` do not block, which allows core to perform computation in paralell. But we need barriers to ensure completion.\n",
    "- **L1 staging**: RISC-V core can not access DRAM data directly and must first copy data to L1. \n",
    "- **InterleavedAddrGen**: To maximize kernel performance, TT-Metaliumuses specific data allocation patterns to place data in DRAM (e.g. interleave memory in multiple banks). To ease the computation of DRAM address for the programmer, TT-Metaliumprovides helper classes such as **InterleavedAddrGen**.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440b797-58b0-4771-9163-78a5c7633e53",
   "metadata": {},
   "source": [
    "## From one Baby RISC-V to Big accelerator engines: adding two integers in Compute\n",
    "\n",
    "Having looked at the configuration and execution of a kernel on a single Baby RISC-V processor, we will now look how to use all 5 RISC-V processors in a pipeline. \n",
    "Indeed, the Baby RISC-V cores are not highly performant by themselves.\n",
    "For optimal performance, we want to:\n",
    "1) Design a pipeline of operations to hide latency and increase throughput\n",
    "2) Perform computation on the significantly more powerful vector and matrix engines. These can only be accessed from compute kernels.\n",
    "\n",
    "The following example perform the same addition between two inputs. But instead of doing everything on a single Baby RISC-V processor, we will have three kernels:\n",
    "- A reader kernel that reads data from DRAM\n",
    "- A compute kernel that perform the addition\n",
    "- A writer kernel that writes back the result to DRAM\n",
    "\n",
    "A more in-depth description of this example can be found [here](https://github.com/tenstorrent/tt-metal/blob/main/tt_metal/programming_examples/add_2_integers_in_compute/add_2_integers_in_compute.md).\n",
    "A similar example with a more complex operation can be also be found [here](\n",
    "Also: https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/examples/eltwise_binary.html\n",
    ").\n",
    "\n",
    "\n",
    "Before checking the code, we can check the structure of this new example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62c0ae-ad36-471c-8f89-8eb08188630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls tt_metal/programming_examples/add_2_integers_in_compute/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257bace-0d7d-4644-a0dd-c6771e61420e",
   "metadata": {},
   "source": [
    "```\n",
    "add_2_integers_in_compute/\n",
    "    - CMakeLists.txt\n",
    "    - add_2_integers_in_compute.cpp\n",
    "    - kernels/\n",
    "        - dataflow/\n",
    "            - reader_binary_1_tile.cpp\n",
    "            - writer_1_tile.cpp\n",
    "        - compute/\n",
    "            - add_2_tiles.cpp\n",
    "```\n",
    "\n",
    "Unlike the previous example (`add_2_integers_in_riscv`) which only had a host file and a single kernel source file, we now have 4 files:\n",
    "- A single host file to configure and execute the kernels (`add_2_integers_in_compute`)\n",
    "- Three kernels: a reader (`reader_binary_1_tile.cpp`), a writer kernel `writer_1_tile.cpp` and a compute kernel (`add_2_tiles.cpp`)\n",
    "\n",
    "Having checked the structure, we can test the program with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157c7d2-152a-44ee-b627-ac4420aab8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./build_Debug_tracy/programming_examples/metal_example_add_2_integers_in_compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a52600-e40f-4f1a-8488-a4a9462f05be",
   "metadata": {},
   "source": [
    "\n",
    "### Kernel Structure \n",
    "\n",
    "Now let's understand the three-kernel architecture for the addition example. Unlike the previous RISC-V example, this one properly utilizes the compute engines (FPU/SFPU) for better performance.\n",
    "\n",
    "#### Reader Kernel (`kernels/dataflow/reader_binary_1_tile.cpp`)\n",
    "\n",
    "Here, the role of the reader kernel is to fetch both inputs from DRAM and send their data to the compute kernel.\n",
    "To do this, we re-use the `noc_async_read_tile()` primitives from the previous `add_2_integers_in_riscv` example. \n",
    "But unlike the single-kernel example, the reader puts data into **Circular Buffers*. \n",
    "\n",
    "Two primitive are needed to write data into a circular buffer:\n",
    "- `cb_reserve_back()`: Reserve a **tile** worth of data at the back of the circular buffer. If the buffer is full then wait until buffer has at least 1 tile worth of available space.  \n",
    "- `cb_push_back()`: Notify compute kernel that data has been written to circular buffer and move the tail of the circular buffer by 1 tile.\n",
    "\n",
    "To copy the data to the reserved space in the circular buffer, we can use the address of the circular buffer (`get_write_ptr(cb)`) as destination for `noc_async_read_tile()`. Indeed, circular buffers are stored in L1, and their data can be written to.\n",
    "\n",
    "As indicated here, both primitives use **tiles** rather than bytes or number of elements as unit. This is for performance reasons: on one hand, communication through circular buffers has an overhead than we want to minimize, and on the other hand, the matrix and vectors engines in the compute kernel use tiles as work unit.  \n",
    "In TT-Metal, a tile typically contains `32*32 = 1024` elements.\n",
    "\n",
    "\n",
    "```cpp\n",
    "void kernel_main() {\n",
    "    // Read parameters from the kernel arguments\n",
    "    uint32_t in0_addr = get_arg_val<uint32_t>(0); // DRAM address of input0 \n",
    "    uint32_t in1_addr = get_arg_val<uint32_t>(1); // DRAM address of input1\n",
    "    \n",
    "    // Circular buffers to write into. \n",
    "    // Each circular buffer has an unique identifier. \n",
    "    constexpr uint32_t cb_in0 = tt::CBIndex::c_0;\n",
    "    constexpr uint32_t cb_in1 = tt::CBIndex::c_1;\n",
    "    \n",
    "    // read the tiles from DRAM into the circular buffers\n",
    "    cb_reserve_back(cb_in0, 1);\n",
    "    uint32_t cb_in0_addr = get_write_ptr(cb_in0);\n",
    "    noc_async_read_tile(0, in0, cb_in0_addr);  // read\n",
    "    noc_async_read_barrier();                  // wait until the read is done\n",
    "    cb_push_back(cb_in0, 1);                   // mark the tile as ready.\n",
    "\n",
    "    // same process for the second input (different circular buffer and input buffer)\n",
    "    cb_reserve_back(cb_in1, 1);\n",
    "    uint32_t cb_in1_addr = get_write_ptr(cb_in1);\n",
    "    noc_async_read_tile(0, in1, cb_in1_addr);\n",
    "    noc_async_read_barrier();\n",
    "    cb_push_back(cb_in1, 1);\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### Writer Kernel (`kernels/dataflow/write_tile.cpp`)\n",
    "\n",
    "The writer reads from the output circular buffer and writes to DRAM:\n",
    "On the other end of the pipeline, the writer kernel looks is the mirrored version of the reader kernel. \n",
    "Instead of reading from DRAM and into a circular buffer, the writer kernel reads from a circular buffer and to DRAM.\n",
    "\n",
    "But while reader used `cb_reserve_back()` and `cb_push_back()` primitive, the writer use two other circular primitives:\n",
    "- `cb_wait_front()`: Wait until circular buffer contains at least a tile worth of data. If circular buffer is empty, then it will wait until producer calls `cb_push_back()`. \n",
    "- `cb_pop_front()`: Free a tile from circular and move the head by 1 tile. If circular buffer was full and producer was waiting with `cb_reserve_back()` then producer will be able to reserve a tile and continue.\n",
    "\n",
    "Just like with the reader, these two primitives are only used to synchronize data exchanges between producer (compute kernel) and writer. \n",
    "As the underlying data is stored in L1, it can be sent directly to DRAM using `noc_async_write_tile()`, with the read address of the circular buffer (`get_read_ptr(cb)`).\n",
    "\n",
    "```cpp\n",
    "void kernel_main() {\n",
    "    uint32_t dst_addr = get_arg_val<uint32_t>(0);\n",
    "\n",
    "    // The circular buffer that we are going to read from and write to DRAM\n",
    "    constexpr uint32_t cb_out0 = tt::CBIndex::c_16;\n",
    "    const uint32_t tile_size_bytes = get_tile_size(cb_out0);\n",
    "\n",
    "    \n",
    "    // Make sure there is a tile in the circular buffer\n",
    "    cb_wait_front(cb_out0, 1);\n",
    "    uint32_t cb_out0_addr = get_read_ptr(cb_out0);\n",
    "    // write the tile to DRAM\n",
    "    noc_async_write_tile(0, dst, cb_out0_addr);\n",
    "    noc_async_write_barrier();  // This will wait until the write is done. As an alternative,\n",
    "                                // noc_async_write_flushed() can be faster because it waits\n",
    "                                // until the write request is sent. In that case, you have to\n",
    "                                // use noc_async_write_barrier() at least once at the end of\n",
    "                                // data movement kernel to make sure all writes are done.\n",
    "    // Mark the tile as consumed\n",
    "    cb_pop_front(cb_out0, 1);\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#### Compute Kernel (`kernels/compute/add_2_tiles.cpp`)\n",
    "\n",
    "The compute kernel is the most complex. Although written as a single file, it's **compiled into three separate binaries** that run on three different RISC-V cores within the Tensix:\n",
    "\n",
    "```cpp\n",
    "namespace NAMESPACE {\n",
    "void MAIN {\n",
    "    uint32_t n_tiles = get_arg_val<uint32_t>(0);\n",
    "    \n",
    "    constexpr auto cb_in0 = tt::CBIndex::c_0;\n",
    "    constexpr auto cb_in1 = tt::CBIndex::c_1;\n",
    "    constexpr auto cb_out0 = tt::CBIndex::c_16;\n",
    "    constexpr uint32_t dst_reg = 0;\n",
    "    \n",
    "    // Initialize the compute engines (runs on all 3 processor)\n",
    "    binary_op_init_common(cb_in0, cb_in1, cb_out0);  // Configure unpacker/packer\n",
    "    add_tiles_init(cb_in0, cb_in1);                  // Configure FPU for addition\n",
    "    \n",
    "    for (uint32_t i = 0; i < n_tiles; i++) {\n",
    "        cb_wait_front(cb_in0, 1);   // [Unpack cprocessorre] Wait for input data\n",
    "        cb_wait_front(cb_in1, 1);\n",
    "        \n",
    "        tile_regs_acquire();        // [Math processor] Acquire Dst registers\n",
    "        add_tiles(cb_in0, cb_in1, 0, 0, dst_reg);  // [Unpack+Math] Add tiles using FPU\n",
    "        tile_regs_commit();         // [Math processor] Transfer Dst to packer\n",
    "        \n",
    "        cb_pop_front(cb_in0, 1);    // [Unpack processor] Release input tiles\n",
    "        cb_pop_front(cb_in1, 1);\n",
    "        \n",
    "        cb_reserve_back(cb_out0, 1); // [Pack processor] Reserve output space\n",
    "        tile_regs_wait();            // [Pack processor] Wait for Dst access\n",
    "        pack_tile(dst_reg, cb_out0); // [Pack processor] Write Dst to circular buffer\n",
    "        tile_regs_release();         // [Pack processor] Release Dst registers\n",
    "        \n",
    "        cb_push_back(cb_out0, 1);   // [Pack processor] Signal output ready\n",
    "    }\n",
    "}\n",
    "}\n",
    "```\n",
    "\n",
    "**The three processors work together:**\n",
    "1. **Unpack processor**: Manages input circular buffers and copies data into internal registers (`SrcA`/`SrcB`) for the Matrix engine (FPU)\n",
    "2. **Math processor**: Controls Matrix and Vector engines (FPU and SFPU), which will write their results to internal register (`Dst` registers). \n",
    "3. **Pack processor**: Takes results from Matrix and Vector engines and writes them to output circular buffers\n",
    "\n",
    "Because the same code is executed by three different Baby RISC-V processors, several synchronization primitives are required to avoid data-races on internal registers.\n",
    "- `tile_regs_acquire()`: Math and Unpack processors claims ownership of internal registers (`Dst` registers) for computation\n",
    "- `tile_regs_commit()`: Math and Unpack processors release ownership of registers\n",
    "- `tile_regs_wait()`: Pack processor waits until internal registers are ready\n",
    "- `tile_regs_release()`: Pack processor releases ownership of internal registers\n",
    "\n",
    "Moreover, the unpack and pack processors re-use the aforementioned circular buffer primitives to received inputs from reader kernel, and send output to writer kernel. \n",
    "\n",
    "**Why initialize?**\n",
    "In our example, the element-wise addition is performed by the Matrix engine. \n",
    "But before we call the operation, we need to configure the Matrix engine as well as the packer and unpackers. \n",
    "\n",
    "To do this, we use the following 'init' functions:\n",
    "- `binary_op_init_common()`: Configures the unpacker/packer for the data formats in the circular buffers\n",
    "- `add_tiles_init()`: Configures the Matrix engine to perform addition (vs. multiply, etc.)\n",
    "- These setup functions tell the hardware HOW to interpret and process the data\n",
    "\n",
    "Having set up the Matrix engine and unpacker/packer, we can perform addition using `add_tiles()`. \n",
    "This will read two tiles worth of data from both input circular buffers, add them together, and write the data to another internal register (0-th `Dst` register).\n",
    "\n",
    "### Summary\n",
    "\n",
    "In this section, you learned:\n",
    "- How to set-up a data-processing pipeline: Reader → Compute → Writer working in parallel via circular buffers\n",
    "- How to use the Circular Buffer API: `cb_reserve_back`/`cb_push_back` (producer) and `cb_wait_front`/`cb_pop_front` (consumer)\n",
    "- How compute kernels work: One source file → three binaries (Unpack/Math/Pack cores)\n",
    "- How internal registers of compute kernels are managed and synchronized using `tile_regs_*` functions\n",
    "- About tiles, which are 32×32 grids and serve as the fundamental unit of computation in TT-Metaliumkernels.\n",
    "- How to set-up Matrix engine to perform basic element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96323c6-3f86-4141-9e9f-7a0c6738c417",
   "metadata": {},
   "source": [
    "## Exercise: Implementation of a Kernel\n",
    "\n",
    "The implementation of a models requires many operations and as many kernels. To simplify the work, TT-NN provides a wide range of operations. \n",
    "However, it is sometimes useful to re-implement a kernel (if it does not exist, or to tune to a specific use-case).\n",
    "\n",
    "In this section, we invite you to re-implement an element-wise kernel that computes the hypotenuse of two inputs: `sqrt(a^2 + b^2)`.\n",
    "\n",
    "To make things easier, we can copy the previous programming example to a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f4a25-7776-4c50-85ce-a3b3fefec114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp -r tt_metal/programming_examples/add_2_integers_in_compute/ tt_metal/programming_examples/my_first_binary_kernel/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2573011b",
   "metadata": {},
   "source": [
    "To be able to compile this example, we add it to `tt_metal/programming_examples/CMakeLists.txt`:\n",
    "\n",
    "```\n",
    "...\n",
    "add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/custom_sfpi_add)\n",
    "add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/custom_sfpi_smoothstep)\n",
    "> add_subdirectory(${CMAKE_CURRENT_SOURCE_DIR}/my_first_binary_kernel)\n",
    "```\n",
    "\n",
    "And rename the target in `tt_metal/programming_examples/my_first_binary_kernel/CMakeLists.txt` to replace `metal_example_add_2_integers_in_compute` to `metal_my_first_binary_kernel`. \n",
    "\n",
    "We can then recompile TT-Metaliumwith this new example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./build_metal.sh --build-tests --debug --build-programming-examples -e --enable-profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2dca57-a8e0-4854-9793-e1ef6983a2c7",
   "metadata": {},
   "source": [
    "\n",
    "To implement `hypot`, we only need to modify the compute kernel to replace addition with hypotenuse computation.\n",
    "\n",
    "\n",
    "```cpp\n",
    "#include <cstdint>\n",
    "#include \"compute_kernel_api/eltwise_binary.h\"\n",
    "#include \"compute_kernel_api/tile_move_copy.h\"\n",
    "\n",
    "namespace NAMESPACE {\n",
    "void MAIN {\n",
    "    constexpr auto cb_in0 = tt::CBIndex::c_0;\n",
    "    constexpr auto cb_in1 = tt::CBIndex::c_1;\n",
    "    constexpr auto cb_out0 = tt::CBIndex::c_16;\n",
    "\n",
    "    // The following sequence of operations are compiled onto the 3 compute cores (Unpack, Math, Pack) in the Tensix\n",
    "    // core. The work together to perform the addition of two input tiles and store the result in the output tile to the\n",
    "    // output circular buffer. Which is then picked up by the writer kernel and written back to DRAM.\n",
    "\n",
    "    // Metalium API Calls                              Involved Processors\n",
    "    // TODO: Use matching init\n",
    "    // ...\n",
    "\n",
    "    // wait for a tile to be ready in the input CBs\n",
    "    cb_wait_front(cb_in0, 1);  // Unpack\n",
    "    cb_wait_front(cb_in1, 1);  // Unpack\n",
    "\n",
    "    // acquire 8 tile registers to perform the addition\n",
    "    tile_regs_acquire();  // Math\n",
    "\n",
    "    // ---- TODO ----\n",
    "    // TODO: Hypotenuse computation goes here\n",
    "    // ...\n",
    "    // ---- END of TODO ----\n",
    "\n",
    "    // signal the packer\n",
    "    tile_regs_commit();  // Math\n",
    "\n",
    "    // packer waits here\n",
    "    tile_regs_wait();  // Pack\n",
    "    // Copy the result from tile registers to the\n",
    "    // output circular buffer (also called packing)\n",
    "    pack_tile(0, cb_out0);  // Pack\n",
    "    // packer releases\n",
    "    tile_regs_release();  // Pack\n",
    "\n",
    "    cb_pop_front(cb_in0, 1);  // Unpack\n",
    "    cb_pop_front(cb_in1, 1);  // Unpack\n",
    "\n",
    "    cb_push_back(cb_out0, 1);  // Pack\n",
    "}\n",
    "}  // namespace NAMESPACE\n",
    "```\n",
    "\n",
    "A full description of available Kernel APIs such as `add_tiles()` can be found [here](https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/apis/kernel_apis.html)\n",
    "\n",
    "__Hint:__ `add_binary_tile()` (SFPU version), `square_tile`, `sqrt_tile()`, `copy_tile()` which all read and write from and to DST registers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ddc05-f4e8-426e-b01b-c16bc3d4fab4",
   "metadata": {},
   "source": [
    "## Relevant useful Resources\n",
    "\n",
    "### Related Repositories\n",
    "\n",
    "- **tt-isa-documentation**: Documentation of Tenstorrent's hardware-specific Open-Source Instruction Set Architecture  \n",
    "  https://github.com/tenstorrent/tt-isa-documentation/\n",
    "\n",
    "- **tt-metal**: Main repository with examples and documentation  \n",
    "  https://github.com/tenstorrent/tt-metal\n",
    "\n",
    "- **tt-forge**: High-level neural network compiler framework  \n",
    "  https://github.com/tenstorrent/tt-forge-fe\n",
    "\n",
    "### Key Documentation\n",
    "\n",
    "- **Metalium Guide**: Comprehensive architecture and programming guide (see link at the top)\n",
    "- **API Reference**: https://docs.tenstorrent.com/tt-metal/latest/tt-metalium/tt_metal/apis/\n",
    "- **Technical Reports**: Performance studies and architecture deep-dives in `tt-metal/tech_reports/`\n",
    "  - Matrix multiplication performance (GEMM_FLOPS)\n",
    "  - Convolution networks (CNNs)\n",
    "  - Attention mechanisms (FlashAttention)\n",
    "  - Multi-chip scaling (TT-Fabric)\n",
    "\n",
    "### Programming Examples\n",
    "\n",
    "The `tt_metal/programming_examples/` directory contains many useful examples:\n",
    "- **hello_world_***: Minimal examples for data movement and compute\n",
    "- **matmul_***: Single-core and multi-core matrix multiplication\n",
    "- **eltwise_***: Element-wise operations (binary, SFPU)\n",
    "- **custom_sfpi_***: Custom vector operations on the SFPU\n",
    "- **distributed/**: Multi-chip programming examples\n",
    "\n",
    "### Debugging Tools\n",
    "\n",
    "**Print debugging**: Use `DPRINT` macro in kernels\n",
    "```cpp\n",
    "DPRINT << \"Value: \" << my_value << \"\\n\";\n",
    "```\n",
    "Then set the environment variable to see output:\n",
    "```bash\n",
    "export TT_METAL_DPRINT_CORES=0,0  # Print from core (0,0)\n",
    "```\n",
    "\n",
    "**Tracy profiler**: Enable profiling during build\n",
    "```bash\n",
    "./build_metal.sh --build-tests --release -e --enable-tracy\n",
    "```\n",
    "\n",
    "### Getting Help\n",
    "\n",
    "- **Documentation**: https://docs.tenstorrent.com/\n",
    "- **GitHub Issues**: https://github.com/tenstorrent/tt-metal/issues\n",
    "- **Discord Community**: Join the Tenstorrent Discord for community support\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
